{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec146d2",
   "metadata": {},
   "source": [
    "# Data Visualization for Titanic open dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befcd1d9",
   "metadata": {},
   "source": [
    "This is an open source dataset of the Titanic and this project is an attempt to manipulate and extract informations from it with Python and scikit-learn.\n",
    "\n",
    "In the end we want to create a confusion matrix of the Titanic Dataset.\n",
    "A Confusion Matrix is an array used in machine learning to evaluate classification performance of a model. It compares predictions to the real values and allow you to visualize where the model is right or wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8666c2",
   "metadata": {},
   "source": [
    "![](../assets/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3bb85",
   "metadata": {},
   "source": [
    "Be sure to have selected the Python envrionnement to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33af1eb6-f9da-432c-9d22-1a42919cca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24672d",
   "metadata": {},
   "source": [
    "# Setting up the project\n",
    "Here we import libraries and we are counting values at null in data. This is a first glance at what we will need to change in our dataset for two reasons:\n",
    "1. First data has to be a numeric value representation (not object)\n",
    "2. Since we manipulate data, a null value will not serve us in visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "997cf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b281377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Titanic dataset\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../assets/titanic/titanic.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWorking on Titanic dataset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m../assets/titanic/titanic.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m data.info()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(data.isnull().sum())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../assets/titanic/titanic.csv'"
     ]
    }
   ],
   "source": [
    "print(\"Working on Titanic dataset\")\n",
    "data = pd.read_csv(\"../assets/titanic/titanic.csv\")\n",
    "data.info()\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91770d8",
   "metadata": {},
   "source": [
    "Here we are witnessing:\n",
    "- `327` missing values for `Cabin`\n",
    "- `86` migging values for `Age`\n",
    "- `1` missing value for `Fare` (which are the prices for the ticket)\n",
    "\n",
    "Theses are the values we'll need to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa5953",
   "metadata": {},
   "source": [
    "# Data Manipulation\n",
    "Since the data is not ready for visualization, we need to manipulate some columns and values to clean the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c720e4b",
   "metadata": {},
   "source": [
    "## Fill Missing Ages\n",
    "First we create a filling function the missing Age values.\n",
    "For that we are looping in the dataFrame (with unique values) and if a pclass in the `Pclass` column is not in out dictionary `age_fill_map` we add it with a median as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825b7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_ages(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    filling missing ages in dataFrame (df)\n",
    "    \"\"\"\n",
    "    age_fill_map = {}\n",
    "\n",
    "    for pclass in df[\"Pclass\"].unique():\n",
    "        if pclass not in age_fill_map:\n",
    "            age_fill_map[pclass] = df[df[\"Pclass\"] == pclass][\"Age\"].median()\n",
    "\n",
    "    # Apply the median onto df if row[\"Age\"] is null otherwize keep the original age\n",
    "    df[\"Age\"] = df.apply(\n",
    "        lambda row: age_fill_map[row[\"Pclass\"]]\n",
    "        if pd.isnull(row[\"Age\"])\n",
    "        else row[\"Age\"],\n",
    "        axis=1,\n",
    "    )\n",
    "    # df[\"Age\"].fillna(df[\"Pclass\"].map(age_fill_map), inplace=True)\n",
    "    print(f\"Age fill map: {age_fill_map}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8180f",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "How we preprocessed data with the dataFrame object:\n",
    "- Drop the columns `PassenerId`,`Name`,`Ticket`,`Cabin` from dataFrame because these values won't help us in seeing who survived in Titanic catastrophe.\n",
    "- We fill the `Embarked` column of `S` if there is no data.\n",
    "- Execute the `fill_missing_age()` function created earlier.\n",
    "- Convert the gender in a binary representation (I hate this but hey, machine is reading 1 an 0).\n",
    "- Add new column `FamilySize` which is a combination of `SibSp` and `Parch` columns (it stands for \"Sibling\" and \"Parent\").\n",
    "- Add new column `IsAlone` because if `FamilySize` is 0 then the passenger is alone.\n",
    "- Group column `FareBin` values in 4 diffrents groups\n",
    "- Group column `AgeBin` values in 0,12,20,40,60 representing ages of passengers (np.inf is for infinite)\n",
    "And write in `/assets/titanic/data_preprocessed.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop unused columns, fill null values and convert in number type\n",
    "    \"\"\"\n",
    "    df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], inplace=True)\n",
    "\n",
    "    # Fill the missing values as \"S\" for Southampton, the most common embarkation point in the data\n",
    "    # df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "    df.drop(columns=[\"Embarked\"], inplace=True)\n",
    "\n",
    "    fill_missing_ages(df)\n",
    "\n",
    "    # Convert Gender for model\n",
    "    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "\n",
    "    # Feature engineering\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]  # parents + children\n",
    "    df[\"IsAlone\"] = np.where(\n",
    "        df[\"FamilySize\"] == 0, 1, 0\n",
    "    )  # where there is no one then insert 1\n",
    "    df[\"FareBin\"] = pd.qcut(\n",
    "        df[\"Fare\"], 4, labels=False\n",
    "    )  # categorization for ticket prices\n",
    "    df[\"AgeBin\"] = pd.cut(\n",
    "        df[\"Age\"], bins=[0, 12, 20, 40, 60, np.inf], labels=False\n",
    "    )  # bins for ranged age of passengers\n",
    "\n",
    "    with open(\"../assets/titanic/data_preprocessed.csv\", \"w\") as f:\n",
    "        df.to_csv(f, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ec806",
   "metadata": {},
   "source": [
    "# Run the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Age fill map: {np.int64(3): np.float64(24.0), np.int64(2): np.float64(26.5), np.int64(1): np.float64(42.0)}\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "print(\"Preprocessing data...\")\n",
    "data = pd.read_csv(\"../assets/titanic/titanic.csv\")\n",
    "preprocessed_data = preprocess_data(data)\n",
    "\n",
    "# Create Features / Target Variables (Make Flashcards)\n",
    "X = preprocessed_data.drop(columns=[\"Survived\"])\n",
    "y = preprocessed_data[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6230e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-playground (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
