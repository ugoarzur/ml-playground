{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec146d2",
   "metadata": {},
   "source": [
    "# Data Visualization for Titanic open dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befcd1d9",
   "metadata": {},
   "source": [
    "This is an open source dataset of the Titanic and this project is an attempt to manipulate and extract informations from it with Python and scikit-learn.\n",
    "\n",
    "In the end we want to create a confusion matrix of the Titanic Dataset.\n",
    "A Confusion Matrix is an array used in machine learning to evaluate classification performance of a model. It compares predictions to the real values and allow you to visualize where the model is right or wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8666c2",
   "metadata": {},
   "source": [
    "![](../assets/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e3bb85",
   "metadata": {},
   "source": [
    "Be sure to have selected the Python envrionnement to run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33af1eb6-f9da-432c-9d22-1a42919cca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2.3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/Ugo.Arzur/dev/tests/ai/ml-playground/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf24672d",
   "metadata": {},
   "source": [
    "# Setting up the project\n",
    "Here we import libraries and we are counting values at null in data. This is a first glance at what we will need to change in our dataset for two reasons:\n",
    "1. First data has to be a numeric value representation (not object)\n",
    "2. Since we manipulate data, a null value will not serve us in visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997cf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b281377d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Titanic dataset\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  418 non-null    int64  \n",
      " 1   Survived     418 non-null    int64  \n",
      " 2   Pclass       418 non-null    int64  \n",
      " 3   Name         418 non-null    object \n",
      " 4   Sex          418 non-null    object \n",
      " 5   Age          332 non-null    float64\n",
      " 6   SibSp        418 non-null    int64  \n",
      " 7   Parch        418 non-null    int64  \n",
      " 8   Ticket       418 non-null    object \n",
      " 9   Fare         417 non-null    float64\n",
      " 10  Cabin        91 non-null     object \n",
      " 11  Embarked     418 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 39.3+ KB\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Working on Titanic dataset\")\n",
    "data = pd.read_csv(\"../assets/titanic/titanic.csv\")\n",
    "data.info()\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91770d8",
   "metadata": {},
   "source": [
    "Here we are witnessing:\n",
    "- `327` missing values for `Cabin`\n",
    "- `86` migging values for `Age`\n",
    "- `1` missing value for `Fare` (which are the prices for the ticket)\n",
    "\n",
    "Theses are the values we'll need to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa5953",
   "metadata": {},
   "source": [
    "# Data Manipulation\n",
    "Since the data is not ready for visualization, we need to manipulate some columns and values to clean the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c720e4b",
   "metadata": {},
   "source": [
    "## Fill Missing Ages\n",
    "First we create a filling function the missing Age values.\n",
    "For that we are looping in the dataFrame (with unique values) and if a pclass in the `Pclass` column is not in out dictionary `age_fill_map` we add it with a median as value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "825b7ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_ages(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    filling missing ages in dataFrame (df)\n",
    "    \"\"\"\n",
    "    age_fill_map = {}\n",
    "\n",
    "    for pclass in df[\"Pclass\"].unique():\n",
    "        if pclass not in age_fill_map:\n",
    "            age_fill_map[pclass] = df[df[\"Pclass\"] == pclass][\"Age\"].median()\n",
    "\n",
    "    # Apply the median onto df if row[\"Age\"] is null otherwize keep the original age\n",
    "    df[\"Age\"] = df.apply(\n",
    "        lambda row: age_fill_map[row[\"Pclass\"]]\n",
    "        if pd.isnull(row[\"Age\"])\n",
    "        else row[\"Age\"],\n",
    "        axis=1,\n",
    "    )\n",
    "    # df[\"Age\"].fillna(df[\"Pclass\"].map(age_fill_map), inplace=True)\n",
    "    print(f\"Age fill map: {age_fill_map}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf8180f",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "How we preprocessed data with the dataFrame object:\n",
    "- Drop the columns `PassenerId`,`Name`,`Ticket`,`Cabin` from dataFrame because these values won't help us in seeing who survived in Titanic catastrophe.\n",
    "- We fill the `Embarked` column of `S` if there is no data.\n",
    "- Execute the `fill_missing_age()` function created earlier.\n",
    "- Convert the gender in a binary representation (I hate this but hey, machine is reading 1 an 0).\n",
    "- Add new column `FamilySize` which is a combination of `SibSp` and `Parch` columns (it stands for \"Sibling\" and \"Parent\").\n",
    "- Add new column `IsAlone` because if `FamilySize` is 0 then the passenger is alone.\n",
    "- Group column `FareBin` values in 4 diffrents groups\n",
    "- Group column `AgeBin` values in 0,12,20,40,60 representing ages of passengers (np.inf is for infinite)\n",
    "And write in `/assets/titanic/data_preprocessed.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4ad44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop unused columns, fill null values and convert in number type\n",
    "    \"\"\"\n",
    "    df.drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], inplace=True)\n",
    "\n",
    "    # Fill the missing values as \"S\" for Southampton, the most common embarkation point in the data\n",
    "    # df[\"Embarked\"].fillna(\"S\", inplace=True)\n",
    "    df.drop(columns=[\"Embarked\"], inplace=True)\n",
    "\n",
    "    fill_missing_ages(df)\n",
    "\n",
    "    # Convert Gender for model\n",
    "    df[\"Sex\"] = df[\"Sex\"].map({\"male\": 1, \"female\": 0})\n",
    "\n",
    "    # Feature engineering\n",
    "    df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"]  # parents + children\n",
    "    df[\"IsAlone\"] = np.where(\n",
    "        df[\"FamilySize\"] == 0, 1, 0\n",
    "    )  # where there is no one then insert 1\n",
    "    df[\"FareBin\"] = pd.qcut(\n",
    "        df[\"Fare\"], 4, labels=False\n",
    "    )  # categorization for ticket prices\n",
    "    df[\"AgeBin\"] = pd.cut(\n",
    "        df[\"Age\"], bins=[0, 12, 20, 40, 60, np.inf], labels=False\n",
    "    )  # bins for ranged age of passengers\n",
    "\n",
    "    with open(\"../assets/titanic/data_preprocessed.csv\", \"w\") as f:\n",
    "        df.to_csv(f, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4ec806",
   "metadata": {},
   "source": [
    "# Run the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Age fill map: {np.int64(3): np.float64(24.0), np.int64(2): np.float64(26.5), np.int64(1): np.float64(42.0)}\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing data\n",
    "print(\"Preprocessing data...\")\n",
    "data = pd.read_csv(\"../assets/titanic/titanic.csv\")\n",
    "preprocessed_data = preprocess_data(data)\n",
    "\n",
    "# Create Features / Target Variables (Make Flashcards)\n",
    "X = preprocessed_data.drop(columns=[\"Survived\"])\n",
    "y = preprocessed_data[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f6230e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-playground (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
